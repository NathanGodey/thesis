@inproceedings{Vaswani+2017,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{meister-etal-2023-natural,
    title = "A Natural Bias for Language Generation Models",
    author = "Meister, Clara  and
      Stokowiec, Wojciech  and
      Pimentel, Tiago  and
      Yu, Lei  and
      Rimell, Laura  and
      Kuncoro, Adhiguna",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-short.22",
    doi = "10.18653/v1/2023.acl-short.22",
    pages = "243--255"
}


@inproceedings{lai-etal-2023-mitigating,
    title = "Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation",
    author = "Lai, Wen  and
      Chronopoulou, Alexandra  and
      Fraser, Alexander",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.953",
    doi = "10.18653/v1/2023.findings-emnlp.953",
    pages = "14279--14294",
}

@inproceedings{
gao2018representation,
title={Representation Degeneration Problem in Training Natural Language Generation Models},
author={Jun Gao and Di He and Xu Tan and Tao Qin and Liwei Wang and Tieyan Liu},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SkEYojRqtm},
}

@misc{godey2024anisotropy,
      title={Anisotropy Is Inherent to Self-Attention in Transformers}, 
      author={Nathan Godey and Éric de la Clergerie and Benoît Sagot},
      year={2024},
      eprint={2401.12143},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{freq-based-dist,
  author       = {Kaitlyn Zhou and
                  Kawin Ethayarajh and
                  Dan Jurafsky},
  title        = {Frequency-based Distortions in Contextualized Word Embeddings},
  journal      = {CoRR},
  volume       = {abs/2104.08465},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.08465},
  eprinttype    = {arXiv},
  eprint       = {2104.08465},
  timestamp    = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2104-08465.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{gemmateam2024gemma,
      title={Gemma: Open Models Based on Gemini Research and Technology}, 
      author={Gemma Team and Thomas Mesnard and Cassidy Hardin and Robert Dadashi and Surya Bhupatiraju and Shreya Pathak and Laurent Sifre and Morgane Rivière and Mihir Sanjay Kale and Juliette Love and Pouya Tafti and Léonard Hussenot and Aakanksha Chowdhery and Adam Roberts and Aditya Barua and Alex Botev and Alex Castro-Ros and Ambrose Slone and Amélie Héliou and Andrea Tacchetti and Anna Bulanova and Antonia Paterson and Beth Tsai and Bobak Shahriari and Charline Le Lan and Christopher A. Choquette-Choo and Clément Crepy and Daniel Cer and Daphne Ippolito and David Reid and Elena Buchatskaya and Eric Ni and Eric Noland and Geng Yan and George Tucker and George-Christian Muraru and Grigory Rozhdestvenskiy and Henryk Michalewski and Ian Tenney and Ivan Grishchenko and Jacob Austin and James Keeling and Jane Labanowski and Jean-Baptiste Lespiau and Jeff Stanway and Jenny Brennan and Jeremy Chen and Johan Ferret and Justin Chiu and Justin Mao-Jones and Katherine Lee and Kathy Yu and Katie Millican and Lars Lowe Sjoesund and Lisa Lee and Lucas Dixon and Machel Reid and Maciej Mikuła and Mateo Wirth and Michael Sharman and Nikolai Chinaev and Nithum Thain and Olivier Bachem and Oscar Chang and Oscar Wahltinez and Paige Bailey and Paul Michel and Petko Yotov and Pier Giuseppe Sessa and Rahma Chaabouni and Ramona Comanescu and Reena Jana and Rohan Anil and Ross McIlroy and Ruibo Liu and Ryan Mullins and Samuel L Smith and Sebastian Borgeaud and Sertan Girgin and Sholto Douglas and Shree Pandya and Siamak Shakeri and Soham De and Ted Klimenko and Tom Hennigan and Vlad Feinberg and Wojciech Stokowiec and Yu-hui Chen and Zafarali Ahmed and Zhitao Gong and Tris Warkentin and Ludovic Peran and Minh Giang and Clément Farabet and Oriol Vinyals and Jeff Dean and Koray Kavukcuoglu and Demis Hassabis and Zoubin Ghahramani and Douglas Eck and Joelle Barral and Fernando Pereira and Eli Collins and Armand Joulin and Noah Fiedel and Evan Senter and Alek Andreev and Kathleen Kenealy},
      year={2024},
      eprint={2403.08295},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{merrill-etal-2022-saturated,
    title = "Saturated Transformers are Constant-Depth Threshold Circuits",
    author = "Merrill, William  and
      Sabharwal, Ashish  and
      Smith, Noah A.",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.49",
    doi = "10.1162/tacl_a_00493",
    pages = "843--856"
}

@inproceedings{
tay2022scale,
title={Scale Efficiently: Insights from Pretraining and Finetuning Transformers},
author={Yi Tay and Mostafa Dehghani and Jinfeng Rao and William Fedus and Samira Abnar and Hyung Won Chung and Sharan Narang and Dani Yogatama and Ashish Vaswani and Donald Metzler},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=f2OYVDyfIB}
}

@misc{petty2023impact,
      title={The Impact of Depth and Width on Transformer Language Model Generalization}, 
      author={Jackson Petty and Sjoerd van Steenkiste and Ishita Dasgupta and Fei Sha and Dan Garrette and Tal Linzen},
      year={2023},
      eprint={2310.19956},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{rajaee-pilehvar-2022-isotropy,
    title = "An Isotropy Analysis in the Multilingual {BERT} Embedding Space",
    author = "Rajaee, Sara  and
      Pilehvar, Mohammad Taher",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.103",
    doi = "10.18653/v1/2022.findings-acl.103",
    pages = "1309--1316",
}

@inproceedings{puccetti-etal-2022-outlier,
    title = "Outlier Dimensions that Disrupt Transformers are Driven by Frequency",
    author = "Puccetti, Giovanni  and
      Rogers, Anna  and
      Drozd, Aleksandr  and
      Dell{'}Orletta, Felice",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.93",
    pages = "1286--1304"
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@inproceedings{biderman2023pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O’Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  booktitle={International Conference on Machine Learning},
  pages={2397--2430},
  year={2023},
  organization={PMLR}
}

@article{low_rank,
author = {N. Kishore Kumar and J. Schneider},
title = {Literature survey on low rank approximation of matrices},
journal = {Linear and Multilinear Algebra},
volume = {65},
number = {11},
pages = {2212-2244},
year = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/03081087.2016.1267104},
URL = {https://doi.org/10.1080/03081087.2016.1267104}
}

@misc{chinchilla_scaling,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tinyllama,
      title={TinyLlama: An Open-Source Small Language Model}, 
      author={Peiyuan Zhang and Guangtao Zeng and Tianduo Wang and Wei Lu},
      year={2024},
      eprint={2401.02385},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{chang-mccallum-2022-softmax,
    title = "Softmax Bottleneck Makes Language Models Unable to Represent Multi-mode Word Distributions",
    author = "Chang, Haw-Shiuan  and
      McCallum, Andrew",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.554",
    doi = "10.18653/v1/2022.acl-long.554",
    pages = "8048--8073"
}

@inproceedings{bis-etal-2021-much,
    title = "Too Much in Common: Shifting of Embeddings in Transformer Language Models and its Implications",
    author = "Bi{\'s}, Daniel  and
      Podkorytov, Maksim  and
      Liu, Xiuwen",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.403",
    doi = "10.18653/v1/2021.naacl-main.403",
    pages = "5117--5130",
}

@misc{wikitext,
      title={Pointer Sentinel Mixture Models},
      author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},
      year={2016},
      eprint={1609.07843},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{rudman-etal-2022-isoscore,
    title = "{I}so{S}core: Measuring the Uniformity of Embedding Space Utilization",
    author = "Rudman, William  and
      Gillman, Nate  and
      Rayne, Taylor  and
      Eickhoff, Carsten",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.262",
    doi = "10.18653/v1/2022.findings-acl.262",
    pages = "3325--3339",
}
@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{almazrouei2023falcon,
      title={The Falcon Series of Open Language Models}, 
      author={Ebtesam Almazrouei and Hamza Alobeidli and Abdulaziz Alshamsi and Alessandro Cappelli and Ruxandra Cojocaru and Mérouane Debbah and Étienne Goffinet and Daniel Hesslow and Julien Launay and Quentin Malartic and Daniele Mazzotta and Badreddine Noune and Baptiste Pannier and Guilherme Penedo},
      year={2023},
      eprint={2311.16867},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 12,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.4.0},
  doi          = {10.5281/zenodo.10256836},
  url          = {https://zenodo.org/records/10256836}
}

@misc{touvron2023llama,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@InProceedings{imdb,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@inproceedings{srebro2003weighted,
  title={Weighted low-rank approximations},
  author={Srebro, Nathan and Jaakkola, Tommi},
  booktitle={Proceedings of the 20th international conference on machine learning (ICML-03)},
  pages={720--727},
  year={2003}
}

@article{intrinsic_d,
title = {Intrinsic dimension estimation: Advances and open problems},
journal = {Information Sciences},
volume = {328},
pages = {26-41},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515006179},
author = {Francesco Camastra and Antonino Staiano},
keywords = {Intrinsic dimension, Curse of dimensionality, Maximum likelihood, Correlation dimension, Dimensionality reduction},
}

@article{scaling_manifold,
  author  = {Utkarsh Sharma and Jared Kaplan},
  title   = {Scaling Laws from the Data Manifold Dimension},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {9},
  pages   = {1--34},
  url     = {http://jmlr.org/papers/v23/20-1111.html}
}


@inproceedings{
jing2022understanding,
title={Understanding Dimensional Collapse in Contrastive Self-supervised Learning},
author={Li Jing and Pascal Vincent and Yann LeCun and Yuandong Tian},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=YevsQ05DEN7}
}

@inproceedings{sigsoftmax,
 author = {Kanai, Sekitoshi and Fujiwara, Yasuhiro and Yamanaka, Yuki and Adachi, Shuichi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sigsoftmax: Reanalysis of the Softmax Bottleneck},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/9dcb88e0137649590b755372b040afad-Paper.pdf},
 volume = {31},
 year = {2018}
}

@misc{lin2021breaking,
      title={Breaking the Softmax Bottleneck for Sequential Recommender Systems with Dropout and Decoupling}, 
      author={Ying-Chen Lin},
      year={2021},
      eprint={2110.05409},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{ngram_svd,
author = {Terashima, Shiro and Takeda, Kazuya and Itakura, Fumitada},
title = {A linear space representation of language probability through SVD of N-gram matrix},
journal = {Electronics and Communications in Japan (Part III: Fundamental Electronic Science)},
volume = {86},
number = {8},
pages = {61-70},
keywords = {singular value decomposition, number of dimensions, entropy, clustering},
doi = {https://doi.org/10.1002/ecjc.10106},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ecjc.10106},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ecjc.10106},
year = {2003}
}



@inproceedings{
softmax_bottleneck,
title={Breaking the Softmax Bottleneck: A High-Rank {RNN} Language Model},
author={Zhilin Yang and Zihang Dai and Ruslan Salakhutdinov and William W. Cohen},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=HkwZSG-CZ},
}

@misc{faysse2024croissantllm,
      title={CroissantLLM: A Truly Bilingual French-English Language Model}, 
      author={Manuel Faysse and Patrick Fernandes and Nuno M. Guerreiro and António Loison and Duarte M. Alves and Caio Corro and Nicolas Boizard and João Alves and Ricardo Rei and Pedro H. Martins and Antoni Bigata Casademunt and François Yvon and André F. T. Martins and Gautier Viaud and Céline Hudelot and Pierre Colombo},
      year={2024},
      eprint={2402.00786},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{beyond_chinchilla,
      title={Beyond Chinchilla-Optimal: Accounting for Inference in Language Model Scaling Laws}, 
      author={Nikhil Sardana and Jonathan Frankle},
      year={2023},
      eprint={2401.00448},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{kaplan_scaling,
  title={Scaling Laws for Neural Language Models},
  author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeff Wu and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.08361},
  url={https://api.semanticscholar.org/CorpusID:210861095}
}

@InProceedings{lambada,
  author    = {Paperno, Denis  and  Kruszewski, Germ\'{a}n  and  Lazaridou,
Angeliki  and  Pham, Ngoc Quan  and  Bernardi, Raffaella  and  Pezzelle,
Sandro  and  Baroni, Marco  and  Boleda, Gemma  and  Fernandez, Raquel},
  title     = {The {LAMBADA} dataset: Word prediction requiring a broad
discourse context},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers)},
  month     = {August},
  year      = {2016},
  address   = {Berlin, Germany},
  publisher = {Association for Computational Linguistics},
  pages     = {1525--1534},
  url       = {http://www.aclweb.org/anthology/P16-1144}
}

@misc{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gao2020pile,
      title={The Pile: An 800GB Dataset of Diverse Text for Language Modeling}, 
      author={Leo Gao and Stella Biderman and Sid Black and Laurence Golding and Travis Hoppe and Charles Foster and Jason Phang and Horace He and Anish Thite and Noa Nabeshima and Shawn Presser and Connor Leahy},
      year={2020},
      eprint={2101.00027},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{ethayarajh-2019-contextual,
    title = "How Contextual are Contextualized Word Representations? {C}omparing the Geometry of {BERT}, {ELM}o, and {GPT}-2 Embeddings",
    author = "Ethayarajh, Kawin",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1006",
    doi = "10.18653/v1/D19-1006",
    pages = "55--65",
}

@inproceedings{rajaee-pilehvar-2021-cluster,
    title = "A Cluster-based Approach for Improving Isotropy in Contextual Embedding Space",
    author = "Rajaee, Sara  and
      Pilehvar, Mohammad Taher",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.73",
    doi = "10.18653/v1/2021.acl-short.73",
    pages = "575--584",
}

@inproceedings{
bondarenko2023quantizable,
title={Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing},
author={Yelysei Bondarenko and Markus Nagel and Tijmen Blankevoort},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=sbusw6LD41}
}

@misc{lee2024owq,
      title={OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models}, 
      author={Changhun Lee and Jungyu Jin and Taesu Kim and Hyungjun Kim and Eunhyeok Park},
      year={2024},
      eprint={2306.02272},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}