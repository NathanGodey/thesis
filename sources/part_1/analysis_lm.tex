
\chapter{On the Scaling Laws of Geographical Representation in Language Models}
\label{chap:geobias}
\input{sources/part_1/geographical/article}

\chapter{Studying Language Model Saturation via the Softmax Bottleneck}
\label{chap:softmax_bottleneck}
\input{sources/part_1/softmax_bottleneck/article}

\chapter{Anisotropy Is Inherent to Self-Attention in Transformers}

\input{sources/part_1/anisotropy/article}
\label{chap:anisotropy}

\chapter*{Conclusion}

Overall, studying distortions and biases in the representation space has allowed us to shed light on bottlenecks and limitations that are inherent to the classical language modeling framework. It also provided insights about the architecture of modern language models, from the dimensionality and sparsity perspectives. 

Beyond the scope of usual interpretability frameworks, that are designed to explain predictions from targeted observations, we advocate for tools that allow analyzing global behaviors of the inner states of language models, in order to provide guidelines towards better paradigm for learning models of natural language.

Finally, we underline that our work, especially \Cref{chap:geobias} and \Cref{chap:softmax_bottleneck}, shows that representation degeneration and frequency-related biases hurt the quality of affected language models, either by degrading their performance or incorporating knowledge bias. In \Cref{part:solutions}, we propose several methods aimed at avoiding degeneration, reducing frequency dependency and mitigating sparsity in language models, in the hope that these methods will indirectly mitigate the identified limitations that are correlated with these phenomena.

% \include{sources/representation_learning}
% \include{sources/language_modeling}
% \include{sources/related_works}
